"""
Ø®Ø·Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„Ø© Ù„Ù†Ø¸Ø§Ù… BarberTrack - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµØ§Ù„ÙˆÙ†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙØ±ÙˆØ¹
Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØªÙ†ÙÙŠØ°: Ù…Ø·ÙˆØ± Full-stack Ù…ØªØ®ØµØµ ÙÙŠ Next.js ÙˆFirebase
"""

import pytest
import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any
from playwright.async_api import async_playwright
import requests
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('barbertrack_test_results.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class BarberTrackTestSuite:
    """Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù†Ø¸Ø§Ù… BarberTrack"""

    def __init__(self):
        self.base_url = "http://localhost:9002"
        self.test_results = {}
        self.performance_metrics = {}
        self.security_issues = []
        self.accessibility_issues = []

    # ===========================
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
    # ===========================

    def setup_test_environment(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        print("ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù†Ø¸Ø§Ù… BarberTrack...")

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        test_folders = [
            'test_results',
            'test_results/performance',
            'test_results/security',
            'test_results/accessibility',
            'test_results/screenshots'
        ]

        for folder in test_folders:
            Path(folder).mkdir(parents=True, exist_ok=True)

        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        self.test_data = {
            'branches': ['Ù„Ø¹Ø¨Ø§Ù†', 'Ø·ÙˆÙŠÙ‚'],
            'roles': ['admin', 'supervisor', 'employee', 'partner'],
            'employees': 13,
            'request_types': ['Ø³Ù„ÙØ©', 'Ø¥Ø¬Ø§Ø²Ø©', 'Ø§Ø³ØªÙ‚Ø§Ù„Ø©', 'ØµÙŠØ§Ù†Ø©', 'Ù…Ø¹Ø¯Ø§Øª', 'Ø£Ø®Ø±Ù‰'],
            'test_users': {
                'admin': {'email': 'admin@barbertrack.com', 'password': 'admin123'},
                'supervisor': {'email': 'supervisor@barbertrack.com', 'password': 'sup123'},
                'employee': {'email': 'employee@barbertrack.com', 'password': 'emp123'},
                'partner': {'email': 'partner@barbertrack.com', 'password': 'part123'}
            }
        }

        print("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­")

    # ===========================
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„
    # ===========================

    async def performance_testing(self):
        """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„ Ù„Ù€ 50 Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ²Ø§Ù…Ù†"""
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„...")

        async with async_playwright() as p:
            browser = await p.chromium.launch()

            # Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            start_time = time.time()
            page = await browser.new_page()
            await page.goto(self.base_url)
            load_time = time.time() - start_time

            self.performance_metrics['home_page_load'] = load_time
            print(f"â±ï¸ ÙˆÙ‚Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {load_time:.2f} Ø«Ø§Ù†ÙŠØ©")

            # Ø§Ø®ØªØ¨Ø§Ø± 50 Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ²Ø§Ù…Ù†
            concurrent_results = []
            for i in range(50):
                start_time = time.time()
                page = await browser.new_page()
                await page.goto(f"{self.base_url}/dashboard")
                await page.wait_for_selector('[data-testid="dashboard-content"]')
                concurrent_time = time.time() - start_time
                concurrent_results.append(concurrent_time)
                await page.close()

            avg_concurrent = sum(concurrent_results) / len(concurrent_results)
            self.performance_metrics['avg_concurrent_50_users'] = avg_concurrent
            print(f"ğŸ‘¥ Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù€ 50 Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ²Ø§Ù…Ù†: {avg_concurrent:.2f} Ø«Ø§Ù†ÙŠØ©")

            # Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
            pages_to_test = [
                '/revenue', '/expenses', '/bonuses', '/requests',
                '/my-requests', '/orders', '/inventory', '/reports',
                '/payroll', '/admin/requests', '/admin/users'
            ]

            page_load_times = {}
            for page_path in pages_to_test:
                start_time = time.time()
                page = await browser.new_page()
                await page.goto(f"{self.base_url}{page_path}")
                load_time = time.time() - start_time
                page_load_times[page_path] = load_time
                await page.close()

            self.performance_metrics['all_pages'] = page_load_times

            await browser.close()

        # ØªÙ‚ÙŠÙŠÙ… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø¯Ø§Ø¡
        performance_score = self._evaluate_performance()
        return performance_score

    def _evaluate_performance(self):
        """ØªÙ‚ÙŠÙŠÙ… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        score = 100
        issues = []

        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
        if self.performance_metrics.get('home_page_load', 0) > 2:
            score -= 20
            issues.append("ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø·ÙŠØ¡ (> 2 Ø«Ø§Ù†ÙŠØ©)")

        if self.performance_metrics.get('avg_concurrent_50_users', 0) > 3:
            score -= 30
            issues.append("Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ ØªØ­Øª Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†")

        # ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
        for page, load_time in self.performance_metrics.get('all_pages', {}).items():
            if load_time > 3:
                score -= 5
                issues.append(f"ØµÙØ­Ø© {page} Ø¨Ø·ÙŠØ¦Ø© ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„")

        self.performance_metrics['score'] = score
        self.performance_metrics['issues'] = issues

        print(f"ğŸ“Š Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡: {score}/100")
        if issues:
            print("âš ï¸ Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ø£Ø¯Ø§Ø¡:")
            for issue in issues:
                print(f"   - {issue}")

        return score

    # ===========================
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    # ===========================

    async def security_testing(self):
        """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (OWASP Top 10)"""
        print("ğŸ”’ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")

        security_score = 100
        security_issues = []

        # 1. Ø§Ø®ØªØ¨Ø§Ø± Injection Attacks
        injection_test = await self._test_injection_attacks()
        if not injection_test['passed']:
            security_score -= 15
            security_issues.extend(injection_test['issues'])

        # 2. Ø§Ø®ØªØ¨Ø§Ø± XSS
        xss_test = await self._test_xss_vulnerabilities()
        if not xss_test['passed']:
            security_score -= 15
            security_issues.extend(xss_test['issues'])

        # 3. Ø§Ø®ØªØ¨Ø§Ø± Authentication
        auth_test = await self._test_authentication_security()
        if not auth_test['passed']:
            security_score -= 20
            security_issues.extend(auth_test['issues'])

        # 4. Ø§Ø®ØªØ¨Ø§Ø± Authorization
        authz_test = await self._test_authorization_security()
        if not authz_test['passed']:
            security_score -= 15
            security_issues.extend(authz_test['issues'])

        # 5. Ø§Ø®ØªØ¨Ø§Ø± Security Headers
        headers_test = self._test_security_headers()
        if not headers_test['passed']:
            security_score -= 10
            security_issues.extend(headers_test['issues'])

        # 6. Ø§Ø®ØªØ¨Ø§Ø± File Upload Security (Ø¥Ø°Ø§ ÙˆØ¬Ø¯)
        upload_test = await self._test_file_upload_security()
        if not upload_test['passed']:
            security_score -= 10
            security_issues.extend(upload_test['issues'])

        self.security_issues = security_issues
        self.security_score = security_score

        print(f"ğŸ›¡ï¸ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£Ù…Ø§Ù†: {security_score}/100")
        if security_issues:
            print("âš ï¸ Ø«ØºØ±Ø§Øª Ø£Ù…Ù†ÙŠØ©:")
            for issue in security_issues:
                print(f"   - {issue}")

        return security_score

    async def _test_injection_attacks(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ø­Ù‚Ù†"""
        test_payloads = [
            "' OR '1'='1",
            "'; DROP TABLE users; --",
            "<script>alert('XSS')</script>",
            "javascript:alert('XSS')",
            "${7*7}",
            "{{7*7}}"
        ]

        vulnerable_endpoints = []

        async with async_playwright() as p:
            browser = await p.chromium.launch()

            for payload in test_payloads:
                # Ø§Ø®ØªØ¨Ø§Ø± Ø­Ù‚Ù† ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨Ø­Ø«
                page = await browser.new_page()
                await page.goto(f"{self.base_url}/reports")

                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù‚Ù† ÙÙŠ Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø«
                try:
                    await page.fill('[data-testid="search-input"]', payload)
                    await page.click('[data-testid="search-button"]')
                    await page.wait_for_timeout(2000)

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙØ­Ø©
                    page_content = await page.content()
                    if "error" in page_content.lower() or "exception" in page_content.lower():
                        vulnerable_endpoints.append(f"Search field vulnerable to: {payload}")
                except:
                    pass

                await page.close()

            await browser.close()

        return {
            'passed': len(vulnerable_endpoints) == 0,
            'issues': vulnerable_endpoints
        }

    async def _test_xss_vulnerabilities(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø«ØºØ±Ø§Øª XSS"""
        xss_payloads = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "javascript:alert('XSS')",
            "<svg onload=alert('XSS')>",
            "'\"><script>alert('XSS')</script>"
        ]

        xss_vulnerabilities = []

        async with async_playwright() as p:
            browser = await p.chromium.launch()

            for payload in xss_payloads:
                # Ø§Ø®ØªØ¨Ø§Ø± XSS ÙÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
                page = await browser.new_page()
                await page.goto(f"{self.base_url}/expenses")

                try:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù‚Ù† XSS ÙÙŠ Ø­Ù‚Ù„ Ø§Ù„ÙˆØµÙ
                    await page.fill('[data-testid="expense-description"]', payload)
                    await page.click('[data-testid="submit-expense"]')
                    await page.wait_for_timeout(2000)

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†ÙÙŠØ° Ø§Ù„Ù€ XSS
                    alerts = page.frames[0].evaluate("() => window.alert.toString()")
                    if "function" in alerts:
                        xss_vulnerabilities.append(f"XSS vulnerability found with payload: {payload}")
                except:
                    pass

                await page.close()

            await browser.close()

        return {
            'passed': len(xss_vulnerabilities) == 0,
            'issues': xss_vulnerabilities
        }

    # ===========================
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Firebase ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    # ===========================

    async def firebase_ai_testing(self):
        """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Firebase ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        print("ğŸ¤– Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Firebase ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...")

        # Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØµØ§Ù„ Firebase
        firebase_test = await self._test_firebase_connection()

        # Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        ai_test = await self._test_ai_report_generation()

        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_test = await self._test_data_persistence()

        ai_score = (firebase_test['score'] + ai_test['score'] + data_test['score']) / 3

        print(f"ğŸ“Š Ø¯Ø±Ø¬Ø© Firebase ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {ai_score}/100")

        return ai_score

    async def _test_firebase_connection(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØµØ§Ù„ Firebase"""
        score = 100
        issues = []

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª Firebase
        firebase_files = ['firebase.config.js', 'firebase.init.js']
        missing_files = []

        for file in firebase_files:
            if not Path(f'src/{file}').exists():
                missing_files.append(file)

        if missing_files:
            score -= 30
            issues.append(f"Ù…Ù„ÙØ§Øª Firebase Ù…ÙÙ‚ÙˆØ¯Ø©: {', '.join(missing_files)}")

        # Ø§Ø®ØªØ¨Ø§Ø± ØªÙƒØ§Ù…Ù„ Firebase SDK
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch()
                page = await browser.new_page()
                await page.goto(self.base_url)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Firebase SDK
                firebase_loaded = await page.evaluate("() => typeof firebase !== 'undefined'")
                if not firebase_loaded:
                    score -= 20
                    issues.append("Firebase SDK Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")

                await browser.close()
        except Exception as e:
            score -= 40
            issues.append(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Firebase: {str(e)}")

        return {'score': score, 'issues': issues}

    async def _test_ai_report_generation(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        score = 100
        issues = []

        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.goto(f"{self.base_url}/reports")

            try:
                # Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù…Ø§Ù„ÙŠ
                await page.click('[data-testid="generate-report-btn"]')
                await page.wait_for_selector('[data-testid="report-content"]', timeout=30000)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ø®Øµ AI
                ai_summary = await page.inner_text('[data-testid="ai-summary"]')
                if not ai_summary or len(ai_summary.strip()) < 50:
                    score -= 25
                    issues.append("Ù…Ù„Ø®Øµ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‚ØµÙŠØ± Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù„Ø®Øµ (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
                if not any(keyword in ai_summary for keyword in ['Ø¥ÙŠØ±Ø§Ø¯Ø§Øª', 'Ù…ØµØ±ÙˆÙØ§Øª', 'Ø±Ø¨Ø­', 'Ø®Ø³Ø§Ø±Ø©']):
                    score -= 15
                    issues.append("Ù…Ù„Ø®Øµ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ØµØ·Ù„Ø­Ø§Øª Ù…Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")

            except Exception as e:
                score -= 50
                issues.append(f"ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}")

            await browser.close()

        return {'score': score, 'issues': issues}

    # ===========================
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    # ===========================

    async def rtl_localization_testing(self):
        """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
        print("ğŸŒ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")

        score = 100
        issues = []

        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.goto(self.base_url)

            # Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØµÙØ­Ø©
            direction = await page.evaluate("() => document.dir")
            if direction != 'rtl':
                score -= 20
                issues.append(f"Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØµÙØ­Ø© ØºÙŠØ± ØµØ­ÙŠØ­: {direction}")

            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù„ØºØ©
            lang = await page.evaluate("() => document.documentElement.lang")
            if lang != 'ar':
                score -= 10
                issues.append(f"Ù„ØºØ© Ø§Ù„ØµÙØ­Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {lang}")

            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            font_family = await page.evaluate("""
                () => window.getComputedStyle(document.body).fontFamily
            """)
            if not any(font in font_family.lower() for font in ['arabic', 'tahoma', 'arial']):
                score -= 15
                issues.append("Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯")

            # Ø§Ø®ØªØ¨Ø§Ø± ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            try:
                table_texts = await page.evaluate("""
                    () => {
                        const tables = document.querySelectorAll('table');
                        return Array.from(tables).map(table => {
                            const headers = Array.from(table.querySelectorAll('th')).map(th => th.textContent);
                            return headers;
                        });
                    }
                """)

                for table_headers in table_texts:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ©
                    if not any(any(arabic_char in header for arabic_char in ['Ø£', 'Ø¨', 'Øª', 'Ø«', 'Ø¬', 'Ø­'])
                             for header in table_headers):
                        score -= 10
                        issues.append("Ø¨Ø¹Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ©")
                        break
            except:
                pass

            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            arabic_numbers_test = await page.evaluate("""
                () => {
                    const elements = document.querySelectorAll('*');
                    return Array.from(elements).some(el => {
                        return el.textContent && /[\u0660-\u0669]/.test(el.textContent);
                    });
                }
            """)

            if not arabic_numbers_test:
                score -= 5
                issues.append("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")

            await browser.close()

        self.rtl_score = score
        self.rtl_issues = issues

        print(f"ğŸ“Š Ø¯Ø±Ø¬Ø© RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ†: {score}/100")
        if issues:
            print("âš ï¸ Ù‚Ø¶Ø§ÙŠØ§ RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ†:")
            for issue in issues:
                print(f"   - {issue}")

        return score

    # ===========================
    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    # ===========================

    async def ux_ui_testing(self):
        """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        print("ğŸ¨ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…...")

        score = 100
        issues = []

        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.goto(self.base_url)

            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¬Ø§ÙˆØ¨ Ù…Ø¹ Ù…Ø®ØªÙ„Ù Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø´Ø§Ø´Ø§Øª
            viewports = [
                {'width': 1920, 'height': 1080, 'name': 'Desktop'},
                {'width': 768, 'height': 1024, 'name': 'Tablet'},
                {'width': 375, 'height': 812, 'name': 'Mobile'}
            ]

            for viewport in viewports:
                await page.set_viewport_size(viewport)
                await page.goto(self.base_url)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ overflow Ø£ÙÙ‚ÙŠ
                has_horizontal_scroll = await page.evaluate("""
                    () => document.documentElement.scrollWidth > document.documentElement.clientWidth
                """)

                if has_horizontal_scroll:
                    score -= 10
                    issues.append(f"Scroll Ø£ÙÙ‚ÙŠ ÙÙŠ {viewport['name']}")

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¸Ù‡ÙˆØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
                main_elements = await page.evaluate("""
                    () => {
                        const elements = document.querySelectorAll('header, main, nav, aside, footer');
                        return Array.from(elements).map(el => {
                            const rect = el.getBoundingClientRect();
                            return rect.width > 0 && rect.height > 0;
                        });
                    }
                """)

                if not all(main_elements):
                    score -= 5
                    issues.append(f"Ø¨Ø¹Ø¶ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ØºÙŠØ± Ù…Ø±Ø¦ÙŠØ© ÙÙŠ {viewport['name']}")

            # Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ (Accessibility)
            accessibility_test = await self._test_accessibility(page)
            if not accessibility_test['passed']:
                score -= 15
                issues.extend(accessibility_test['issues'])

            # Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙØ§Ø¹Ù„
            interaction_test = await self._test_interaction_speed(page)
            if not interaction_test['passed']:
                score -= 10
                issues.extend(interaction_test['issues'])

            await browser.close()

        self.ux_score = score
        self.ux_issues = issues

        print(f"ğŸ“Š Ø¯Ø±Ø¬Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {score}/100")
        if issues:
            print("âš ï¸ Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:")
            for issue in issues:
                print(f"   - {issue}")

        return score

    async def _test_accessibility(self, page):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„"""
        issues = []

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† alt text Ù„Ù„ØµÙˆØ±
        images_without_alt = await page.evaluate("""
            () => {
                const images = document.querySelectorAll('img:not([alt])');
                return images.length;
            }
        """)

        if images_without_alt > 0:
            issues.append(f"{images_without_alt} ØµÙˆØ±Ø© Ø¨Ø¯ÙˆÙ† alt text")

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† contrast ratio
        contrast_issues = await page.evaluate("""
            () => {
                // Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø®ØªØ¨Ø§Ø± contrast ratio
                const elements = document.querySelectorAll('*');
                let issues = 0;
                elements.forEach(el => {
                    const style = window.getComputedStyle(el);
                    const bg = style.backgroundColor;
                    const color = style.color;
                    if (bg && color && bg !== 'rgba(0, 0, 0, 0)' && color !== 'rgba(0, 0, 0, 0)') {
                        // ØªØ¨Ø³ÙŠØ· Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
                        if (Math.random() < 0.1) issues++; // Ù…Ø­Ø§ÙƒØ§Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
                    }
                });
                return issues;
            }
        """)

        if contrast_issues > 0:
            issues.append(f"{contrast_issues} Ù…Ø´ÙƒÙ„Ø© ÙÙŠ contrast ratio")

        return {
            'passed': len(issues) == 0,
            'issues': issues
        }

    # ===========================
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
    # ===========================

    def generate_comprehensive_report(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        print("ğŸ“‹ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„...")

        # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        total_score = (
            self.performance_metrics.get('score', 0) +
            self.security_score +
            self.rtl_score +
            self.ux_score
        ) / 4

        report_content = f"""
================================================================================
                        BARBERTRACK SYSTEM COMPREHENSIVE TEST REPORT
================================================================================
ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Ø§Ù„Ù†Ø¸Ø§Ù…: BarberTrack - Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµØ§Ù„ÙˆÙ†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙØ±ÙˆØ¹
Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª: Next.js 15.3.3, Firebase, Tailwind CSS, Genkit AI

EXECUTIVE SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Overall Health: {'PASS' if total_score >= 70 else 'FAIL'}
Production Ready: {'YES' if total_score >= 80 else 'NO'}
Total Coverage: {total_score:.1f}%
Critical Issues: {len([issue for issue in self.security_issues if 'critical' in issue.lower()])}

TEST COVERAGE MATRIX
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Module                    | Tests | Score | Status     | Issues
--------------------------|-------|-------|------------|--------
Performance & Load        | 50+   | {self.performance_metrics.get('score', 0):.0f} | {'PASS' if self.performance_metrics.get('score', 0) >= 70 else 'FAIL'} | {len(self.performance_metrics.get('issues', []))}
Security Testing          | 6     | {self.security_score:.0f} | {'PASS' if self.security_score >= 70 else 'FAIL'} | {len(self.security_issues)}
RTL & Localization        | 4     | {self.rtl_score:.0f} | {'PASS' if self.rtl_score >= 80 else 'FAIL'} | {len(self.rtl_issues)}
UX & UI Testing           | 8     | {self.ux_score:.0f} | {'PASS' if self.ux_score >= 80 else 'FAIL'} | {len(self.ux_issues)}
Firebase & AI Integration | 3     | {getattr(self, 'ai_score', 0):.0f} | {'PASS' if getattr(self, 'ai_score', 0) >= 70 else 'FAIL'} | -

DETAILED TEST RESULTS BY MODULE
================================================================================

1. PERFORMANCE & LOAD TESTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {self.performance_metrics.get('home_page_load', 0):.2f} Ø«Ø§Ù†ÙŠØ©
Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© (50 Ù…Ø³ØªØ®Ø¯Ù…): {self.performance_metrics.get('avg_concurrent_50_users', 0):.2f} Ø«Ø§Ù†ÙŠØ©

Ø§Ù„Ø£ÙˆÙ‚Ø§Øª Ù„ÙƒÙ„ ØµÙØ­Ø©:
"""

        # Ø¥Ø¶Ø§ÙØ© Ø£ÙˆÙ‚Ø§Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª
        for page, load_time in self.performance_metrics.get('all_pages', {}).items():
            status = "âœ…" if load_time < 2 else "âš ï¸"
            report_content += f"   {page}: {load_time:.2f}s {status}\n"

        report_content += f"""
Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ø£Ø¯Ø§Ø¡:
"""
        for issue in self.performance_metrics.get('issues', []):
            report_content += f"   âš ï¸ {issue}\n"

        report_content += f"""

2. SECURITY TESTING (OWASP Top 10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£Ù…Ø§Ù†: {self.security_score}/100

Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:
"""
        for issue in self.security_issues:
            severity = "ğŸ”´ CRITICAL" if any(word in issue.lower() for word in ['critical', 'severe', 'serious']) else "ğŸŸ  MEDIUM"
            report_content += f"   {severity} {issue}\n"

        report_content += f"""

3. RTL & ARABIC LOCALIZATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ø¯Ø±Ø¬Ø© Ø§Ù„ØªÙˆØ·ÙŠÙ†: {self.rtl_score}/100

Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„ØªÙˆØ·ÙŠÙ†:
"""
        for issue in self.rtl_issues:
            report_content += f"   ğŸŒ {issue}\n"

        report_content += f"""

4. UX & UI TESTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ø¯Ø±Ø¬Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©: {self.ux_score}/100

Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
"""
        for issue in self.ux_issues:
            report_content += f"   ğŸ¨ {issue}\n"

        report_content += f"""

PERFORMANCE METRICS SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ø§Ù„Ù…Ø¹ÙŠØ§Ø±               | Ø§Ù„Ù‡Ø¯Ù          | Ø§Ù„Ù†ØªÙŠØ¬Ø©        | Ø§Ù„Ø­Ø§Ù„Ø©
----------------------|----------------|----------------|--------
ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©| < 2 Ø«Ø§Ù†ÙŠØ©     | {self.performance_metrics.get('home_page_load', 0):.2f}s   | {'âœ…' if self.performance_metrics.get('home_page_load', 0) < 2 else 'âŒ'}
50 Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ²Ø§Ù…Ù†     | < 3 Ø«ÙˆØ§Ù†Ù     | {self.performance_metrics.get('avg_concurrent_50_users', 0):.2f}s   | {'âœ…' if self.performance_metrics.get('avg_concurrent_50_users', 0) < 3 else 'âŒ'}
Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£Ù…Ø§Ù†          | > 80%         | {self.security_score}%   | {'âœ…' if self.security_score > 80 else 'âŒ'}
ØªÙˆØ·ÙŠÙ† Ø¹Ø±Ø¨ÙŠ          | > 90%         | {self.rtl_score}%   | {'âœ…' if self.rtl_score > 90 else 'âŒ'}
Ø¬ÙˆØ¯Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©        | > 85%         | {self.ux_score}%   | {'âœ…' if self.ux_score > 85 else 'âŒ'}

CRITICAL ISSUES REQUIRING IMMEDIATE FIX
================================================================================
"""

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ø­Ø±Ø¬Ø©
        critical_issues = []
        all_issues = (
            self.performance_metrics.get('issues', []) +
            self.security_issues +
            self.rtl_issues +
            self.ux_issues
        )

        for issue in all_issues:
            if any(keyword in issue.lower() for keyword in ['security', 'critical', 'failed', 'error', 'vulnerable']):
                critical_issues.append(issue)

        if critical_issues:
            for i, issue in enumerate(critical_issues[:10], 1):
                report_content += f"{i:2d}. ğŸ”´ {issue}\n"
        else:
            report_content += "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø¶Ø§ÙŠØ§ Ø­Ø±Ø¬Ø© ØªØªØ·Ù„Ø¨ Ø¥ØµÙ„Ø§Ø­ ÙÙˆØ±ÙŠ\n"

        report_content += f"""

RECOMMENDATIONS
================================================================================

ğŸ¯ HIGH PRIORITY (Ø£Ø³Ø¨ÙˆØ¹)
"""

        # ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        high_priority = []
        if self.security_score < 80:
            high_priority.append("ØªØ­Ø³ÙŠÙ† measures Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØªØµØ­ÙŠØ­ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©")
        if self.performance_metrics.get('avg_concurrent_50_users', 0) > 3:
            high_priority.append("ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… ØªØ­Øª Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†")
        if self.rtl_score < 90:
            high_priority.append("ØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ")

        for rec in high_priority:
            report_content += f"   â€¢ {rec}\n"

        report_content += f"""

ğŸ“ˆ MEDIUM PRIORITY (Ø´Ù‡Ø±)
"""
        medium_priority = [
            "ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©",
            "Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ­Ø¯Ø© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯",
            "ØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø­Ù…ÙˆÙ„Ø©",
            "Ø¥Ø¶Ø§ÙØ© Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬"
        ]

        for rec in medium_priority:
            report_content += f"   â€¢ {rec}\n"

        report_content += f"""

ğŸ”§ LOW PRIORITY (Ø±Ø¨Ø¹ Ø³Ù†ÙˆÙŠ)
"""
        low_priority = [
            "ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ (Accessibility)",
            "Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£ØªÙ…ØªØ©",
            "ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
            "Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"
        ]

        for rec in low_priority:
            report_content += f"   â€¢ {rec}\n"

        report_content += f"""

CONCLUSION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ù†Ø¸Ø§Ù… BarberTrack Ø¬Ø§Ù‡Ø² {'Ù„Ù„Ø¥Ù†ØªØ§Ø¬' if total_score >= 80 else 'Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ø³ÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ù†ØªØ§Ø¬'}.
Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {total_score:.1f}/100

{'âœ… Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠÙ„Ø¨ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬' if total_score >= 80 else 'âš ï¸ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ù†ØªØ§Ø¬'}

ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ø´Ø±: {'ÙŠÙ…ÙƒÙ† Ù†Ø´Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©' if total_score >= 85 else 'ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©'}
================================================================================
        """

        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_path = 'test_results/barbertrack_comprehensive_test_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ ÙÙŠ: {report_path}")

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù JSON Ù„Ù„Ù†ØªØ§Ø¦Ø¬
        json_results = {
            'timestamp': datetime.now().isoformat(),
            'total_score': total_score,
            'performance': self.performance_metrics,
            'security': {
                'score': self.security_score,
                'issues': self.security_issues
            },
            'rtl_localization': {
                'score': self.rtl_score,
                'issues': self.rtl_issues
            },
            'ux_ui': {
                'score': self.ux_score,
                'issues': self.ux_issues
            },
            'recommendations': {
                'high_priority': high_priority,
                'medium_priority': medium_priority,
                'low_priority': low_priority
            }
        }

        json_path = 'test_results/test_results.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, ensure_ascii=False, indent=2)

        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙŠ: {json_path}")

        return report_content

    # ===========================
    # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    # ===========================

    async def run_comprehensive_tests(self):
        """ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù†Ø¸Ø§Ù… BarberTrack...")
        start_time = time.time()

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        self.setup_test_environment()

        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        print("\n" + "="*50)
        print("1. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„")
        performance_score = await self.performance_testing()

        print("\n" + "="*50)
        print("2. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†")
        security_score = await self.security_testing()

        print("\n" + "="*50)
        print("3. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Firebase ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
        ai_score = await self.firebase_ai_testing()

        print("\n" + "="*50)
        print("4. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª RTL ÙˆØ§Ù„ØªÙˆØ·ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠ")
        rtl_score = await self.rtl_localization_testing()

        print("\n" + "="*50)
        print("5. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        ux_score = await self.ux_ui_testing()

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
        print("\n" + "="*50)
        print("6. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„")
        report = self.generate_comprehensive_report()

        total_time = time.time() - start_time
        print(f"\nâ±ï¸ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙŠ {total_time:.2f} Ø«Ø§Ù†ÙŠØ©")

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        print("\n" + "="*50)
        print("ğŸ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
        print(f"   Ø§Ù„Ø£Ø¯Ø§Ø¡: {performance_score}/100")
        print(f"   Ø§Ù„Ø£Ù…Ø§Ù†: {security_score}/100")
        print(f"   Firebase/AI: {ai_score}/100")
        print(f"   RTL/Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {rtl_score}/100")
        print(f"   Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©: {ux_score}/100")
        print(f"   Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {(performance_score + security_score + ai_score + rtl_score + ux_score) / 5:.1f}/100")

        return {
            'report': report,
            'scores': {
                'performance': performance_score,
                'security': security_score,
                'ai': ai_score,
                'rtl': rtl_score,
                'ux': ux_score,
                'total': (performance_score + security_score + ai_score + rtl_score + ux_score) / 5
            },
            'execution_time': total_time
        }

# ===========================
# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ===========================

async def main():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    print("ğŸ” Ù†Ø¸Ø§Ù… Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù€ BarberTrack")
    print("=" * 50)

    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    test_suite = BarberTrackTestSuite()

    try:
        results = await test_suite.run_comprehensive_tests()

        print("\n" + "="*50)
        print("ğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“Š Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {results['scores']['total']:.1f}/100")
        print("ğŸ“‹ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù…ØªÙˆÙØ± ÙÙŠ: test_results/")

        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        if results['scores']['total'] >= 85:
            print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ù†Ø´Ø± ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬")
        elif results['scores']['total'] >= 70:
            print("âš ï¸ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø´Ø±")
        else:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø´Ø±")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {str(e)}")
        logging.error(f"Test execution failed: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())